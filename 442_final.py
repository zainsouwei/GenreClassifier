# -*- coding: utf-8 -*-
"""442_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rYA3nlJTNFLDL9vqLrpsVTvqGUuj6-RZ

#EECS 442 Final: Song Recommender

__Please provide the following information__
(e.g. Andrew Owens, ahowens):

Andrew Kim, adkimmy

Zain Souweidane, zainsou

Matthew Moliassa, mmolia

# Starting

Run the following code to import the modules you'll need.
"""

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
import numpy as np, matplotlib as mpl, matplotlib.pyplot as plt, urllib, os
import scipy.ndimage # For image filtering
import scipy.stats as st # for gaussian
import math # for cos , sin
import imageio # For loading images
import urllib.request
from os import listdir
from os.path import isfile, join
import random
import torch.nn as nn

import pandas as pd
import seaborn as sns
import sklearn as skl
import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm
from sklearn.model_selection import train_test_split
import librosa
import librosa.display

import torch
from google.colab import drive

"""import torch and use gpu"""

# import torch
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
if torch.cuda.is_available():
    print("Using the GPU!")
else:
    print("WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.")

"""Mount Drive to access dataset!!!"""

# from google.colab import drive
drive.mount('/content/drive')

"""## Load X, y from google drive.

X: mel spectograms (1000, 128, 672)
y: labels (1000,)
"""

#Load X and y
with open('/content/drive/Shareddrives/442 Final/dataset/outfile_X', 'rb') as f:
  X = np.load(f)
with open('/content/drive/Shareddrives/442 Final/dataset/outfile_y', 'rb') as f:
  y = np.load(f)

"""# Get Data (Run iff outfile_X and outfile_y not in drive)

Our dataset genres contains 10 genres with 100 tracks each:
1.   blues
2.   classical
3.   country
4.   disco
5.   hiphop
6.   jazz
7.   metal
8.   pop
9.   reggae
10.  rock

Track Example: country.00099.wav
"""

paths = [] # all genre paths
paths.append('/content/drive/Shareddrives/442 Final/dataset/genres/blues/')
paths.append('/content/drive/Shareddrives/442 Final/dataset/genres/classical/')
paths.append('/content/drive/Shareddrives/442 Final/dataset/genres/country/')
paths.append('/content/drive/Shareddrives/442 Final/dataset/genres/disco/')
paths.append('/content/drive/Shareddrives/442 Final/dataset/genres/hiphop/')
paths.append('/content/drive/Shareddrives/442 Final/dataset/genres/jazz/')
paths.append('/content/drive/Shareddrives/442 Final/dataset/genres/metal/')
paths.append('/content/drive/Shareddrives/442 Final/dataset/genres/pop/')
paths.append('/content/drive/Shareddrives/442 Final/dataset/genres/reggae/')
paths.append('/content/drive/Shareddrives/442 Final/dataset/genres/rock/')

genre_names = ["blues", "classical", "country", "disco", "hiphop", "jazz", "metal", "pop", "reggae", "rock"]

track_paths = [] # list of lists of pathnames to each wav track.
for path in paths:
  genre_data = []
  for filename in os.listdir(path):
    genre_data.append(path + filename)
  track_paths.append(genre_data)
track_paths = np.array(track_paths)

"""## Plot Graphs For 1 Song From Each Genre

"""

def plot_spectrograms(track_paths, genre_names):
  '''
  Plots melspectrograms for each genre
  '''
  # Defining the subplots
  fig, ax = plt.subplots(nrows = 2, ncols = 5, figsize = (25,10))
  ax = ax.ravel() # Turning ax into a matrix to make it easier to work with

  # Loading in the audio file
  for i in range(len(track_paths)):
    y, sr = librosa.core.load(track_paths[i][0])
    
    # Computing the mel spectrogram
    spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)
    spect = librosa.power_to_db(spect, ref=np.max)
    
    # Displaying the mel spectrogram 
    librosa.display.specshow(spect, y_axis = 'mel', fmax = 8000, x_axis = 'time', ax = ax[i])
    ax[i].set_title(str(genre_names[i]))


def plot_wavplots(track_paths, genre_names):
  '''
  Plots wavplots for each genre
  '''  
  # Defining the subplots
  fig, ax = plt.subplots(nrows = 2, ncols = 5, figsize = (25,10))
  ax = ax.ravel() # Turning ax into a matrix to make it easier to work with

  # Loading in the audio file
  for i in range(len(track_paths)):
    y, sr = librosa.core.load(track_paths[i][0])
    
    # Displaying the mel spectrogram 
    librosa.display.waveplot(y, sr=sr, x_axis = 'time', ax = ax[i])
    ax[i].set_title(str(genre_names[i]))

plot_spectrograms(track_paths, genre_names) # Mel Spectrograms
plot_wavplots(track_paths, genre_names) # Waveplots

"""##Read and Extract Mel Spectograms from Audio Files

1. Takes in track paths, computes the mel spectrogram for each audio file, normalizes size, and stores in a numpy array. 
    
2. Creates a list of genre labels and maps them to numeric values.
    
"""

def extract_mel_spectrogram(track_paths):
    '''
    Returns:
    X (array): array of mel spectrogram data from all wav files
    y (array): array of the corresponding genre labels in numeric form
    '''
    
    # Creating empty lists for mel spectrograms and labels
    labels = []
    mel_specs = []
    
    # Looping through each file in the directory
    for i in range(len(track_paths)):
        print("genre: ", i)
        for file in track_paths[i]:
            # Loading in the audio file
            y, sr = librosa.core.load(file)
            
            # Extracting the label and adding it to the list
            labelone = str(file).split('.')[0]
            labeltwo = labelone.split('/')
            label = labeltwo[len(labeltwo)- 1]
            labels.append(label)
            
            # Computing the mel spectrograms
            spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)
            spect = librosa.power_to_db(spect, ref=np.max)
            
            # Adjusting the size to be 128 x 660 FIXME: might want to make maxsize variable not hardcoded
            #if spect.shape[1] != 660:
            spect.resize(128,672, refcheck=False)
                
            # Adding the mel spectrogram to the list
            mel_specs.append(spect)
        
    # Converting the list or arrays to an array
    X = np.array(mel_specs)
    
    # Converting labels to numeric values
    labels = pd.Series(labels)
    label_dict = {
        'blues': 0,
        'classical': 1,
        'country': 2,
        'disco': 3,
        'hiphop': 4,
        'jazz': 5,
        'metal': 6,
        'pop': 7,
        'reggae': 8,
        'rock': 9
    }
    y = labels.map(label_dict)
    
    # Returning the mel spectrograms and labels
    return X, y

# X.shape : (1000, 128, 672)
# y.shape : (1000,)
X, y = extract_mel_spectrogram(track_paths)

"""DONT RUN THIS UNLESS YOU RAN THE CELL ABOVE

"""

# Save X and y to google drive
with open('/content/drive/Shareddrives/442 Final/dataset/outfile_X', 'wb') as f:
  np.save(f, X)
with open('/content/drive/Shareddrives/442 Final/dataset/outfile_y', 'wb') as f:
  np.save(f, y)

"""# Prepare data (train, test)
70% Training, 30% Test data


"""

# X_train : (700,128,672)       y_train : (700,)
# X_test : (300,128,672)        y_test :  (300,)
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y, test_size=.3)

#Process Data
# Scaling our data to be between 0 and 1 using the minimum value from above
print(X_train.shape)
min = X_train.min()
X_train /= min #FIXME: Do we need scaling?
X_test /= min

#reshape X_train and X_test
X_train = X_train.reshape(700, 1, 128, 672) #FIXME: Is 1 in the right spot?
X_train  = torch.from_numpy(X_train)
X_test = X_test.reshape(300, 1, 128, 672) #FIXME: Is 1 in the right spot?
X_test = torch.from_numpy(X_test)

#One hot encoding our labels
y_train = np.array(y_train)
y_test = np.array(y_test)
y_train = torch.from_numpy(y_train)
y_test = torch.from_numpy(y_test)
# y_train = torch.nn.functional.one_hot(y_train)
# y_test = torch.nn.functional.one_hot(y_test)

#Make trainloader
dataset = torch.utils.data.TensorDataset(X_train, y_train)
testset = torch.utils.data.TensorDataset(X_test, y_test)
batchsize = 5
trainloader = torch.utils.data.DataLoader(dataset, batch_size=batchsize, shuffle=True) #FIXME: Tweak batch size 13 will cause CUDA out of memory
testloader = torch.utils.data.DataLoader(testset, batch_size=batchsize, shuffle=False) #FIXME: Tweak batch size

"""# VGGish_CNN

"""

class VGG_CNN(nn.Module):
  def __init__(self):
    super(VGG_CNN, self).__init__() # FIXME: Do we need this?

    self.model = torch.nn.Sequential(
            nn.Conv2d(1, 64, 3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2),

            nn.Conv2d(64, 128, 3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2),

            nn.Conv2d(128, 256, 3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(256, 256, 3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2),

            nn.Conv2d(256, 512, 3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(512, 512, 3, stride=1, padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2, stride=2),
            nn.MaxPool2d(2, stride=2)
    )
  
    #self.avgpool = nn.AdaptiveAvgPool2d((5, 5)) #FIXME

    self.classifier = nn.Sequential(
            nn.Linear(43008, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, 4096),
            nn.ReLU(inplace=True),
            nn.Linear(4096, 128),
            nn.ReLU(inplace=True),
            nn.Linear(128, 10),
            nn.ReLU(inplace=True)
    )

  def forward(self,x):
    x = self.model(x).permute(0, 2, 3, 1).contiguous()
    x = x.view(x.size(0), -1)
    x = self.classifier(x)
    return x
  
net = VGG_CNN()
net.to(device) # Uses GPU

"""Model Summary"""

from torchsummary import summary


summary(net, (1, 128, 672),batchsize)

"""# Train Net

4 Distinct Sections:
1. Forward Pass
2. Loss Function
3. Backward Pass

4. Weight Update

## Progress Bar
Allows us to visualize the training steps
"""

!pip install pkbar
import pkbar
import time

pbar = pkbar.Pbar(name='loading and processing dataset', target=10)

for i in range(10):
    time.sleep(0.1)
    pbar.update(i)

"""## Define Loss Function and Optimizer
https://ruder.io/optimizing-gradient-descent/

"""

import torch.optim as optim

criterion = nn.CrossEntropyLoss()
#default lr = 1e-2
# optimizer = torch.optim.SGD(net.parameters(), lr=0.3, momentum=0.9)
optimizer = optim.Adam(net.parameters(), lr=1e-5) # FIXME: Adjust lr hyperparameter

"""## Load Trained Net from Google Drive

Run this cell if we already saved a well trained net. Ignore this cell if you want to train the net again.
"""

path = F"/content/drive/Shareddrives/442 Final/dataset/my_net.pt"
net.load_state_dict(torch.load(path))

"""## Train Function"""

# Define number of epochs
num_epochs = 100

# tr_acc_history: list, training accuracy history. Recording freq: one epoch.
tr_acc_history = []
tr_loss_history = []

# TRAIN FUNCTION
for epoch in range(num_epochs):  # loop over the dataset multiple times
    # Print out epoch information
    kbar = pkbar.Kbar(target=140, epoch=epoch, num_epochs=num_epochs, width=8, always_stateful=False)
    print('-' * 10)

    running_loss = 0.0
    running_corrects = 0

    for i, data in enumerate(trainloader, 0):
        # get the inputs; data is a list of [inputs, labels]
        inputs, labels = data
        #print(inputs)
        #print(labels)
        #inputs, labels = inputs.cuda(), labels.cuda()
        inputs = inputs.to(device)
        labels = labels.to(device)
        # zero the parameter gradients
        optimizer.zero_grad()

        # forward + backward + optimize
        outputs = net(inputs.float()) #FIXME: might not need to be float
        #print("\n\n\n", outputs, "\n\n\n")
        max, preds = torch.max(outputs, 1) # FIXME
        #print("\n\n\n", labels.data, "\n\n\n")
        #print(labels)
        #print(outputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        ############################# Update after each batch ##################################
        kbar.update(i, values=[("loss", loss)])
        ########################################################################################

        # print statistics
        #print("\n\n\n", inputs.size(0), "\n\n\n")
        running_loss += loss.item() * inputs.size(0) #FIXME inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)

    # Calculate epoch_loss and epoch_acc
    epoch_loss = running_loss / len(trainloader.dataset)
    epoch_acc = running_corrects.double() / len(trainloader.dataset)
    print(' Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))

    tr_loss_history.append(epoch_loss)
    tr_acc_history.append(epoch_acc)

print('Finished Training')

"""###Save net so we dont have to train every time
DO NOT RUN THIS UNLESS YOU WANT TO SAVE A NEWLY TRAINED NET

"""

path = F"/content/drive/Shareddrives/442 Final/dataset/my_net.pt"
torch.save(net.state_dict(), path)

"""# Visualize Feature Maps and Filters

"""

#TOD0
#https://towardsdatascience.com/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c

"""## Visualize the training loss and accuracy"""

# Training loss history
plt.figure()
plt.plot(tr_loss_history)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training Loss History')
plt.show()

# Training accuracy history
plt.figure()
plt.plot(tr_acc_history)
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training Accuracy History')
plt.show()

"""# Test Net"""

# Test FUNCTION
running_loss = 0.0
running_corrects = 0

#test_acc_history = []
#test_loss_history = []

for i, data in enumerate(testloader, 0):
  inputs, labels = data
  inputs = inputs.to(device)
  labels = labels.to(device)
  optimizer.zero_grad()

  # forward + backward + optimize
  outputs = net(inputs.float()) #FIXME: might not need to be float

  max, preds = torch.max(outputs, 1) # FIXME

  loss = criterion(outputs, labels)
  print(labels)
  print(outputs)
  # print statistics
  running_loss += loss.item() * inputs.size(0) #FIXME inputs.size(0)
  running_corrects += torch.sum(preds == labels.data)
  
  #test_loss_history.append(loss.item() * inputs.size(0))
  #test_acc_history.append(torch.sum(preds == labels.data))


# Calculate epoch_loss and epoch_acc
test_loss = running_loss / len(testloader.dataset)
test_acc = running_corrects.double() / len(testloader.dataset)
print(' Loss: {:.4f} Acc: {:.4f}'.format(test_loss, test_acc))
print('Finished Testing')

"""# Test With Our Data"""

def extract_own(song):
    path = song
    track_paths = []
    for filename in os.listdir(path):
      track_paths.append(path + filename)
    track_paths = np.array(track_paths)
    # Creating empty lists for mel spectrograms and labels
    labels = []
    mel_specs = []
    
    
    # Looping through each file in the directory
    for file in track_paths:
      # Loading in the audio file
      name = str(file)
      time = librosa.core.get_duration(filename=file) 
      if time < 30:
        print("Error time too short")
        continue
      time = (time/2) - 15
      y, sr = librosa.load(file,offset=time,duration=30)

      # Extracting the label and adding it to the list
      labels.append(name)
      print(name)      
      # Computing the mel spectrograms
      spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)
      spect = librosa.power_to_db(spect, ref=np.max)
       
      # Adjusting the size to be 128 x 660 FIXME: might want to make maxsize variable not hardcoded
      spect.resize(128,672, refcheck=False)
          
      # Adding the mel spectrogram to the list
      mel_specs.append(spect)
        
    # Converting the list or arrays to an array
    X = np.array(mel_specs)
    y = labels
    
    # Returning the mel spectrograms and labels
    return X, y

def prep_songs(s,t):
    #Process Data
    # Scaling our data to be between 0 and 1 using the minimum value from above
    s /= -80 #FIXME: Do we need scaling?

    #reshape X_train and X_test
    s2 = s.reshape(len(s), 1, 128, 672)
    s3  = torch.from_numpy(s2)

    t2 = np.array(t)
    # zt2 = torch.from_numpy(zt2)
    #Make trainloader
    songset = torch.utils.data.TensorDataset(s3)
    batchsize = 1
    songloader = torch.utils.data.DataLoader(songset, batch_size=batchsize, shuffle=False) #FIXME: Tweak batch size 13 will cause CUDA out of memory
    return songloader

def classify_songs(songloader,t):
    #Classify Playlist
    allsongs = []
    songnames = []
    for i, data in enumerate(songloader, 0):
      inputs = data[0]
      outputs = inputs
      inputs = inputs.to(device)
      optimizer.zero_grad()
      # forward + backward + optimize
      outputs = net(inputs.float()) #FIXME: might not need to be float
      allsongs.append(outputs)
      songnames.append(t[i])
    allsongs = np.array(allsongs)
    # del inputs
    # torch.cuda.empty_cache() #FIXME: maybe remove later
    return allsongs, songnames

import matplotlib.pyplot as plt
from scipy.special import softmax

def summarize_songs(allsongs):
    fig = plt.figure()
    ax = fig.add_axes([0,0,1,1])
    genres = ['Blues', 'Classical', 'Country', 'Disco', 'HipHop','Jazz','Metal','Pop','Reggae','Rock']
    songs = [0,0,0,0,0,0,0,0,0,0]
    songs = np.array(songs)
    for song in allsongs:
      song = np.array(song.cpu().detach().numpy())
      songs = songs + song[0]

    #norm = np.linalg.norm(songs)
    norm = np.sum(songs)
    final = songs/norm 
    #final = softmax(songs)
    ax.bar(genres,final)
    plt.show()
    return final

zs, zt = extract_own('/content/drive/Shareddrives/442 Final/dataset/zain_songs/')
zainloader = prep_songs(zs,zt)

zainsongs, songnames = classify_songs(zainloader,zt)

zaingenres = summarize_songs(zainsongs)
print(zaingenres)
print(np.sum(zaingenres))

"""# Test Similarity Within and Between Genres

"""

ks, kt = extract_own('/content/drive/Shareddrives/442 Final/dataset/Jazz/Kind of Blue/')
kindofloader = prep_songs(ks,kt)

kindofsongs, kindofsongnames = classify_songs(kindofloader,kt)

kindofgenres = summarize_songs(kindofsongs)
print(kindofgenres)
print(np.sum(kindofgenres))

ls, lt = extract_own('/content/drive/Shareddrives/442 Final/dataset/Jazz/A Love Supreme/')
lovesupremeloader = prep_songs(ls,lt)

lovesupremesongs, lovesupremesongnames = classify_songs(lovesupremeloader,lt)

lovesupremegenres = summarize_songs(lovesupremesongs)
print(lovesupremegenres)
print(np.sum(lovesupremegenres))

ms, mt = extract_own('/content/drive/Shareddrives/442 Final/dataset/Metal/')
metalloader = prep_songs(ms,mt)

metalsongs, metalsongnames = classify_songs(metalloader,mt)

metalgenres = summarize_songs(metalsongs)
print(metalgenres)
print(np.sum(metalgenres))

matthews, matthewt = extract_own('/content/drive/Shareddrives/442 Final/dataset/matthew_songs/')
matthewloader = prep_songs(matthews,matthewt)

matthewsongs, matthewsongnames = classify_songs(matthewloader,matthewt)

matthewgenres = summarize_songs(matthewsongs)
print(matthewgenres)
print(np.sum(matthewgenres))

#compare similarity by taking euclidean distance of averages
from scipy.spatial import distance

def dist(group1,group2):
  distan = distance.euclidean(group1,group2)
  distan = distan/(2**.5)
  distan = 1 - distan
  print(distan*100,"%")
zaingenres = np.array([0.03594521,0.13783042, 0.,0.20442739, 0.097877, 0.19686243,
 0., 0.21282384, 0., 0.11423371])
kindofgenres = np.array([0.14792528, 0.37335751, 0.,0.,0.05989792, 0.38578502,0.,0.03303426, 0.,0.])
lovesupremegenres = np.array([0.08893941, 0., 0.,0.91106059, 0.,0.,0.,0.,0.,0.])
metalgenres = np.array([0., 0.05355488, 0., 0.18765634, 0., 0.,0.08272262, 0.11505686, 0.,0.5610093 ])
matthewgenres = np.array([0.01613353, 0.21392894, 0., 0.14713058, 0.11734656, 0.14797792,
 0.00268222, 0.29228669, 0., 0.06251357])
onegenres = np.array([1, 0, 0., 0., 0., 0.,
 0., 0., 0., 0.])
twogenres = np.array([0, .1, 0.2, 0.1, 0.1, 0.1,
 0.1, 0.1, 0.1, 0.1])
print("Similarity between Kind of Blue and Zain's Playlist")
dist(zaingenres,kindofgenres)
print("Similarity between Kind of Blue and Kind of Blue")
dist(kindofgenres,kindofgenres)
print("Similarity between Love Supreme and Kind of Blue")
dist(lovesupremegenres,kindofgenres)
print("Similarity between a Slipknot album and Kind of Blue")
dist(metalgenres,kindofgenres)
print("Similarity between Zain's playlist and Matthew's playlist")
dist(matthewgenres,zaingenres)
print("Two Different")
dist(onegenres,twogenres)